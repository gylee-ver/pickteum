import { Metadata } from 'next'
import { redirect, notFound } from 'next/navigation'
import { headers } from 'next/headers'
import supabase from '@/lib/supabase'
import { generateSocialMeta } from '@/lib/social-meta'

// ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ ë²„ì „
// export const dynamic = 'force-dynamic'

// ìˆ˜ì • í•„ìš”
// export const dynamic = 'force-dynamic' // ì´ ì¤„ ì œê±° ë˜ëŠ” ì£¼ì„
export const revalidate = 300 // 5ë¶„ë§ˆë‹¤ ì¬ê²€ì¦ (ì†Œì…œ ë¯¸ë””ì–´ ìºì‹œ ê³ ë ¤)

// ê¸°ë³¸ ë©”íƒ€ë°ì´í„° í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
function getLibDefaultMetadata(): Metadata {
  return {
    title: 'í”½í‹ˆ - í‹ˆìƒˆì‹œê°„ì„ ì´ìŠˆì¶©ì „ íƒ€ì„ìœ¼ë¡œ!',
    description: 'ë°”ìœ ì¼ìƒ ì† í‹ˆìƒˆì‹œê°„ì— ë§Œë‚˜ëŠ” í•µì‹¬ ì´ìŠˆ! ê±´ê°•, ìŠ¤í¬ì¸ , ê²½ì œ, ì •ì¹˜, ë¼ì´í”„, í…Œí¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ë‰´ìŠ¤ì™€ ì½˜í…ì¸ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.',
    robots: {
      index: true,
      follow: true,
    },
  }
}

// í¬ë¡¤ëŸ¬ ê°ì§€ í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
function isCrawler(userAgent: string): boolean {
  const crawlerPatterns = [
    'facebookexternalhit',
    'Facebot',
    'Twitterbot',
    'LinkedInBot',
    'WhatsApp',
    'Googlebot',
    'bingbot',
    'Slackbot',
    'TelegramBot',
    'Discord',
    'Applebot',
    'PinterestBot',
    'redditbot',
    'crawler',
    'spider',
    'bot'
  ]
  
  const lowerUserAgent = userAgent.toLowerCase()
  return crawlerPatterns.some(pattern => lowerUserAgent.includes(pattern.toLowerCase()))
}

// ğŸ”¥ SEO ìµœì í™” ë©”íƒ€ë°ì´í„° ìƒì„± (ì†Œì…œ ë¯¸ë””ì–´ ê³µìœ  ê¸°ëŠ¥ ì™„ì „ ë³´ì¡´)
export async function generateMetadata({ params }: { params: Promise<{ code: string }> }): Promise<Metadata> {
  console.log('ğŸ”¥ SEO ìµœì í™” ë‹¨ì¶• URL ë©”íƒ€ë°ì´í„° v5.0')
  
  try {
    const { code } = await params
    
    if (!code || typeof code !== 'string' || code.length !== 6) {
      return getLibDefaultMetadata()
    }
    
    // ğŸ”¥ íƒ€ì„ì•„ì›ƒ ì¦ê°€ë¡œ ì•ˆì •ì„± í–¥ìƒ
    const { data: article, error } = await Promise.race([
      supabase
        .from('articles')
        .select(`
          id, 
          title, 
          content, 
          seo_description, 
          thumbnail, 
          author, 
          published_at, 
          updated_at,
          category:categories(name)
        `)
        .eq('short_code', code)
        .eq('status', 'published')
        .single(),
      new Promise((_, reject) => setTimeout(() => reject(new Error('Timeout')), 8000))
    ]) as any
    
    if (error || !article) {
      return getLibDefaultMetadata()
    }
    
    // ì„¤ëª… ìƒì„±
    let description = article.seo_description
    if (!description && article.content) {
      const plainText = article.content.replace(/<[^>]*>/g, '').trim()
      description = plainText.substring(0, 160) + (plainText.length > 160 ? '...' : '')
    }
    description = description || 'í”½í‹ˆ ì•„í‹°í´'
    
    // ğŸ”¥ ë‹¨ì¶• URLìš© ì™„ì „í•œ ë©”íƒ€ë°ì´í„° (ì†Œì…œ ë¯¸ë””ì–´ ê³µìœ  ì™„ì „ ë³´ì¡´)
    const metadata = {
      ...generateSocialMeta({
        title: article.title, // ë¸Œëœë“œëª… ì—†ì´ ìˆœìˆ˜ ì œëª©ë§Œ
        description,
        imageUrl: article.thumbnail || 'https://www.pickteum.com/pickteum_og.png',
        url: `https://www.pickteum.com/article/${article.id}`, // ğŸ”¥ ì›ë³¸ ì•„í‹°í´ URLë¡œ ì„¤ì •
        type: 'article',
        publishedTime: article.published_at,
        modifiedTime: article.updated_at,
        section: Array.isArray(article.category) ? article.category[0]?.name : article.category?.name,
        content: article.content, // í‚¤ì›Œë“œ ì¶”ì¶œìš©
        categoryName: Array.isArray(article.category) ? article.category[0]?.name : article.category?.name
      }),
      // ğŸ”¥ robots.txtì—ì„œ ê²€ìƒ‰ì—”ì§„ ì°¨ë‹¨í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì†Œì…œ ë¯¸ë””ì–´ìš©ìœ¼ë¡œë§Œ ìµœì í™”
      robots: {
        index: false, // robots.txtì—ì„œ ì´ë¯¸ ì°¨ë‹¨ë¨
        follow: true,
      },
      // ğŸ”¥ ë‹¨ì¶• URLìš© ì¶”ê°€ ì„¤ì •
      alternates: {
        canonical: `https://www.pickteum.com/article/${article.id}` // ì •ê·œ URL ì„¤ì •
      }
    }
    
    console.log('ğŸ”¥ SEO ìµœì í™” ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ')
    return metadata
    
  } catch (error) {
    console.error('ğŸ”¥ ë©”íƒ€ë°ì´í„° ìƒì„± ì˜¤ë¥˜:', error)
    return getLibDefaultMetadata()
  }
}

// í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸ - ğŸ”¥ ì†Œì…œ ë¯¸ë””ì–´ ê³µìœ ì™€ ë’¤ë¡œê°€ê¸° ê¸°ëŠ¥ ì™„ì „ ë³´ì¡´
export default async function ShortCodePage({ params }: { params: Promise<{ code: string }> }) {
  const { code } = await params
  
  if (!code || typeof code !== 'string' || code.length !== 6) {
    notFound()
  }
  
  // User-Agent í™•ì¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
  const headersList = await headers()
  const userAgent = headersList.get('user-agent') || ''
  
  console.log('ğŸ” User-Agent:', userAgent)
  console.log('ğŸ¤– í¬ë¡¤ëŸ¬ ì—¬ë¶€:', isCrawler(userAgent))
  
  const { data: article, error } = await supabase
    .from('articles')
    .select('id, title, views')
    .eq('short_code', code)
    .eq('status', 'published')
    .single()
  
  if (error || !article) {
    notFound()
  }
  
  // ì¡°íšŒìˆ˜ ì¦ê°€ (ë°±ê·¸ë¼ìš´ë“œ - ê¸°ì¡´ ìœ ì§€)
  supabase
    .from('articles')
    .update({ views: (article.views || 0) + 1 })
    .eq('id', article.id)
    .then()
  
  // ğŸ”¥ í¬ë¡¤ëŸ¬ì¸ ê²½ìš°: ìƒ‰ì¸ ìƒì„±ì„ ìœ„í•œ ê°œì„ ëœ HTML ë°˜í™˜ (ì†Œì…œ ë¯¸ë””ì–´ ê¸°ëŠ¥ ë³´ì¡´)
  if (isCrawler(userAgent)) {
    console.log('ğŸ¤– í¬ë¡¤ëŸ¬ ê°ì§€ - ìƒ‰ì¸ ìµœì í™”ëœ HTML ë°˜í™˜')
    return (
      <div style={{ display: 'none' }}>
        <h1>{article.title}</h1>
        {/* ğŸ”¥ noindex ì œê±° - ìƒ‰ì¸ ìƒì„± í—ˆìš©í•˜ë©´ì„œ ì†Œì…œ ë¯¸ë””ì–´ ë©”íƒ€ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ */}
        <meta name="robots" content="index, follow" />
        <meta name="description" content={`${article.title} - í”½í‹ˆ`} />
        <link rel="canonical" href={`https://www.pickteum.com/article/${article.id}`} />
        {/* í¬ë¡¤ëŸ¬ê°€ ë©”íƒ€ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ìˆë„ë¡ HTML ì œê³µ */}
      </div>
    )
  }
  
  // ğŸ”¥ ì¼ë°˜ ì‚¬ìš©ìì¸ ê²½ìš°: ì¦‰ì‹œ ë¦¬ë‹¤ì´ë ‰íŠ¸ (ë’¤ë¡œê°€ê¸° ê¸°ëŠ¥ ì™„ì „ ë³´ì¡´)
  console.log('ğŸ‘¤ ì¼ë°˜ ì‚¬ìš©ì - ë¦¬ë‹¤ì´ë ‰íŠ¸')
  redirect(`/article/${article.id}`)
} 